---
title: "Step3a_data_cleaning"
authors: "B.Littleford-Colquhoun & T.Divoll"
date: "2023-09-21"
output: 
  html_document:
  df_print: paged
  toc: true
params:
  todaydate = r'Sys.date()'
  user =
  project_code = 
  seq_dates = []
  output_path = 
  
---
```{r include=FALSE}
## Only needed for knitr to render this notebook
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, readxl, stringr, spgs, filesstrings)
```

#### Collect all the final results from each sequencing run
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env

cp **/*/merged/*.fastq $output_path
```

Now that you've inspected all the controls and potentially bad samples, and moved them out of the working folder, we rerun the merging steps and clean the final merged data set.

#### Combine remaining sequences into one FASTA and dereplicate
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

obiuniq -m sample *_id.fastq --without-progress-bar > all.uniq.fasta
obicount all.uniq.fasta --without-progress-bar
```

#### Filter results to just `count` and `merged_sample` attributes in FASTA headers
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

obiannotate -k count -k merged_sample all.uniq.fasta > $$ ; mv $$ all.uniq.fasta
```

#### Inspect the `count` attribute
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

# get the counting statistics on the ‘count’ attribute
{
obistat -c count all.uniq.fasta --without-progress-bar | sort -nk1 | head -20 | column -t 
} | tee -a seq_count_table_no_controls.txt
```

#### Create a tabulated file for counts per sequence read
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

obitab -o all.uniq.fasta > all.uniq.tab
```

#### Filter out sequences by abundance and length
Keep only the sequences having a count greater or equal to `min_read_length` and a length shorter than `max_read_length` bp (this should be changed depending on marker and filtering criteria)
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

todaydate=$(date +%Y%m%d) # grab today's date from the system

obigrep -l $min_read_length -L $max_read_length -p 'count>=2' all.uniq.fasta > ${todaydate}_all.uniq.fasta
```

#### Clean the sequences for PCR/sequencing errors (sequence variants)
We keep the head sequences (-H option) that are sequences with no variants with a count greater than 5% of their own count (-r 0.05 option). 
**Note:**This step takes a while.
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

todaydate=$(date +%Y%m%d)

obiclean -s merged_sample -r $clean_threshold -H ${todaydate}_all.uniq.fasta > ${todaydate}_alluniq.clean.fasta
```
#### Create a tabulated file to check the number of sequence reads in each sample

```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd $output_path

todaydate=$(date +%Y%m%d)

obitab -o ${todaydate}_alluniq.clean.fasta > ${todaydate}_alluniq.clean.tab

obicount ${todaydate}_alluniq.clean.fasta --without-progress-bar
```

#### Take notes
These notebooks will remain in your dated analysis folder, use this space for any final notes on the cleaned data set: