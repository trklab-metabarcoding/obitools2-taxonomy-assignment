---
title: "Step 4a - Phyloseq global"
output: html_document
date: "2024-04-25"
html_document:
  df_print: paged
  toc: true
params:
    #don't change these
    todaydate: !r (format(Sys.Date(), "%Y%m%d"))
    user: !r Sys.getenv("LOGNAME")
    data_path: "/oscar/data/tkartzin/projects"
    ref_lib_path: "/oscar/data/tkartzin/global_ref_lib"
 
    #update these for your analysis
    project_code: "test"
    taxa_division: "PLN"
    region_of_interest: "P6"
    step_3_analysis_date: "20240502" #if running on the same day as Step 3, this will be `todaydate`, otherwise enter the date when you ran Step 3
   ## latest_global_db_date: "20231205" #look in ref_lib_path for the most recent global reference library you want to use 
    metadata_file: "test_phyloseq_metadata.csv"
---

## Create a Phyloseq Object
This notebook will use your data with taxonomy assigned from the latest global reference database to create a phyloseq object for downstream analyses. We make the assumption that this
```{r setup, include=FALSE}
## Only needed for knitr to render this notebook
knitr::opts_chunk$set(echo = TRUE)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, phyloseq, vegan, vegetarian, scales, datawizard) #this takes a few minutes
here::i_am("./Step4a_create_phyloseq_global.Rmd")
```

## Read in data
This code block will use the tabulated file created in Step 3 and a list of samples
```{r}
input_path <- file.path(params$data_path, params$project_code, "merged_runs", params$step_3_analysis_date)

data_global <- read.csv(file.path(input_path, sprintf("%s_global_alluniq.clean.tag.ann.tab", params$step_3_analysis_date)), sep="\t", header=TRUE)

data_samples <- read.csv(file.path(input_path, params$metadata_file))
```

## Filter data file to keep just what we need
```{r}
size <- dim(data_global) #number of rows and columns
print(paste0("Number of rows in data: ", size[1]))
print(paste0("Number of columns in data: ", size[2]))

best_id_col <- find_columns(data_global, starts_with("best_identity"))
best_match_col <- find_columns(data_global, starts_with("best_match"))

data_global <- data_global %>% 
  select(-contains("obiclean_status"))
  
global_keep <- data_global[which(data_global[,best_id_col]==1),]

global_keep$scientific_name <- make.unique(as.character(global_keep$scientific_name))

keep_rows <- nrow(global_keep)
print(paste0("Number of rows kept: ", keep_rows))
```

## Make a table to represent the counts of each OTU in each sample
```{r}
OTU_table <- global_keep[,grep("sample\\.", colnames(global_keep))]
names(OTU_table) <- gsub(pattern = "sample.", replacement = "", x = names(OTU_table))
rownames(OTU_table) <- sub("^", "P", rownames(OTU_table))
```

## Make a taxonomy table
```{r}
tax_table <- global_keep[,-grep("sample\\.", colnames(global_keep))]
tax_table <- relocate(tax_table, id, definition, {{ best_id_col }}, {{ best_match_col }}, count, .after = last_col())
tax_table2 <- as.matrix(tax_table)
rownames(tax_table2) <- sub("^", "P", rownames(tax_table2))
```

## Do some cleaning before making the final Phyloseq object
```{r}
rownames(data_samples) <- data_samples$SampleID
samples <- sample_data(data_samples)
OTU <- otu_table(OTU_table, taxa_are_rows = TRUE)
TAX <- tax_table(tax_table2)

if (identical(sample_names(OTU), sample_names(samples))){
  print("Your samples are in the right order. Proceed with making your final RDS file!")
} else {
  print("Something is out of order. Make sure the samples in your metadata file match the order in your OTU. Please fix and rerun this notebook.")
}
```

## Create the final Phyloseq object
```{r}
rds_file<- phyloseq(OTU, TAX, samples) 
saveRDS(rds_file, file.path(input_path, paste0(params$project_code, "_diet_global_", params$todaydate, ".rds")))
```