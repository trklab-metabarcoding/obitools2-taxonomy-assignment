---
title: "Step 4b - Phyloseq global and local"
subtitle: "Create phyloseq object using global and local output."
authors: "TR Kartzinel, BL Littleford-Colquhoun, HK Hoff, TJ Divoll"
date: "2024-04-25"
output: 
  html_notebook:
  keep_md: TRUE
  df_print: paged
  toc: true
params:
    #don't change these
    user: !r Sys.getenv("LOGNAME")
    data_path: "/oscar/data/tkartzin/projects"
    global_ref_lib_path: "/oscar/data/tkartzin/global_ref_lib"
    local_ref_lib_path: "/oscar/data/tkartzin/local_ref_lib"
 
    #update these for your analysis
    step_3b_analysis_date: "20240502" #YYYYMMDD
    step_3c_analysis_date: "20240502" #YYYYMMDD
    project_code: "test"
    taxa_division: "PLN"
    region_of_interest: "P6"
    metadata_file: "test_phyloseq_metadata.csv"
    percent_match: 1 # value between 0-1; percent match between reference sequence and your sequence
    RRA_threshold: 0.05 # 5%
---

## Create a Phyloseq Object
This notebook will use your data with taxonomy assigned from the latest global reference database as well as the latest project-specific local database to create a Phyloseq object for downstream analyses.
```{r setup, include=FALSE}
## Only needed for knitr to render this notebook
knitr::opts_chunk$set(echo = TRUE)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, phyloseq, vegan, vegetarian, scales, datawizard, ggplot2, ggrepel)
here::i_am("./Step4a_create_phyloseq_global.Rmd")
```

Make some functions we'll use later.
```{r}
#function to calculate standard errors
se<-function(x) sd(x)/sqrt(length(x))

#function to pull characters from right instead of left
substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}
```

## Read in data
This code block will use the tabulated file created in Step 3 and a list of samples; it loads the cleaned global and local databases.
```{r}
input_path <- file.path(params$data_path, params$project_code, "merged_runs", sprintf("%s_%s", params$step_3c_analysis_date, params$user))

data_global <- read.csv(file.path(input_path, sprintf("%s_global_alluniq.clean.tag.ann.tab", params$step_3b_analysis_date)), sep="\t", header=TRUE)

data_local <- read.csv(file.path(input_path, sprintf("%s_local_alluniq.clean.tag.ann.tab", params$step_3c_analysis_date)), sep="\t", header=TRUE)

data_samples <- read.csv(params$metadata_file)
```

### Collect so insights on the shape of data
Are there the same number of sequences in your local and global files?
```{r}
if (length(which(data_local$id != data_global$id)) == 0){
  print("Your files have the same number of sequences.")
} else {
  print("There is a mismatch in file lengths. Please check inputs and rerun Step 3.")
}
```

### Rename the default column X to SampleID
```{r}
colnames(data_samples)[colnames(data_samples) == "X"] ="SampleID"
```

### Filter the data to only keep 100% matches in the local set
```{r}
size <- dim(data_local) #number of rows and columns
print(paste0("Number of rows in local data: ", size[1]))
print(paste0("Number of columns in local data: ", size[2]))

best_id_col_local <- find_columns(data_local, starts_with("best_identity"))

data_local <- data_local %>% 
  select(-contains("obiclean_status"))

local_keep <- data_local[which(data_local[[best_id_col_local]]==params$percent_match),]

local_keep_rows <- nrow(local_keep)
print(paste0("Number of local rows kept: ", local_keep_rows))
```


### Filter the data to only keep 100% matches in the global set
Global only keeps perfect matches if they are not already present in the local set of matches
```{r}
size <- dim(data_global) #number of rows and columns
print(paste0("Number of rows in global data: ", size[1]))
print(paste0("Number of columns in global data: ", size[2]))

best_id_col <- find_columns(data_global, starts_with("best_identity"))
best_match_col <- find_columns(data_global, starts_with("best_match"))

data_global <- data_global %>% 
  select(-contains("obiclean_status"))
  
global_keep <- data_global[intersect(which(data_global[[best_id_col]] == params$percent_match), which(data_local[[best_id_col_local]]!= params$percent_match)),]

global_keep$scientific_name <- make.unique(as.character(global_keep$scientific_name))

print(paste0("Number of global rows kept: ", nrow(global_keep)))
```

### Combine the local and global datasets
Combine local and additional global libraries into a database called "keep" for exploratory analyses
```{r}
global_keepKEEP <- global_keep
names(global_keepKEEP) <- names(local_keep)
keep <- rbind(local_keep, global_keepKEEP)
```

### Explore the distribution of sequences
Find out distribution of the sequences you toss both locally and globally (i.e., do some match multiple species perfectly, or anything new in GenBank?)

```{r}
local_global_toss <- data_local[which(data_local$id %in% keep$id==F),] #tells you how many taxa didn't have 100% matches 

print(paste0("The number of sequences not matching at 100%: ", dim(local_global_toss)[1]))
```

### Look at the seqs with highest read counts for matches >98%
```{r}
local_global_toss <- local_global_toss[order(local_global_toss$count,decreasing=T),]
head(local_global_toss)
# may be a couple of taxa we should look at that have 1-2 matches at ~98% match with high read count 
```
### Look at a histogram of %match < 1 for the tossed samples
```{r}
hist(local_global_toss[,best_id_col_local])
```

### Count up 100% matches in each family with the local library
```{r}
local_keep %>% count(family_name, sort = TRUE)
```
### Count up 100% matches in each genera with the local library
```{r}
local_keep %>% count(genus_name, sort = TRUE)
```
### Count up 100% matches in each family with the global library
```{r}
global_keep_families <- global_keep %>% count(family_name, sort = TRUE)
global_keep_families
write.csv(global_keep_families, file.path(input_path, "global_keep_familes.csv"))
```
### Count up 100% matches in each genera with the local library
```{r}
global_keep_genera <- global_keep %>% count(genus_name, sort = TRUE)
global_keep_genera
write.csv(global_keep_genera, file.path(input_path, "global_keep_genera.csv"))
```

## Inspect the 90-99% matches
```{r}
local_nineties <- filter(data_local, between(data_local[[best_id_col_local]], 0.9, 1)) %>%
  arrange(desc(best_id_col_local))
local_nineties %>% count(family_name, sort = TRUE) #families with lots of reads matching at 90-99.99% 
```

```{r}
global_nineties <- filter(data_global, between(data_global[[best_id_col]], 0.9, 1)) %>%
  arrange(desc(best_id_col))
global_nineties %>% count(family_name, sort = TRUE) #families with lots of reads matching at 90-99.99% 
```
Filter for records in the global that are a 100% match not already matched at 100% in the local db.
```{r}
global_nineties_keep <- global_nineties[intersect(which(global_nineties[[best_id_col]]==params$percent_match), which(data_local[[best_id_col_local]]!=params$percent_match)),]
```

## Generate summary statistics for publication
#### Median and max for local and global counts
```{r}
print(paste0("The median counts for the local keep subset: ", median(local_keep$count))); print(paste0("The median counts for the global keep subset: ", median(global_keep$count))); 
print(paste0("The maximum counts for the local keep subset: ",max(local_keep$count))); print(paste0("The maximum counts for the global keep subset: ",max(global_keep$count)))
```
#### Sample read depths
This will make tables with the depths for each sample in each data subset.
```{r}
depth <- as.data.frame(t(colSums(data_local[,grep("sample\\.", colnames(data_local))])))
depth_local_only <- as.data.frame(t(colSums(local_keep[,grep("sample\\.", colnames(local_keep))])))
depth_global_only <- as.data.frame(t(colSums(global_keep[,grep("sample\\.", colnames(global_keep))])))
depth_local_and_global <- as.data.frame(t(colSums(keep[,grep("sample\\.", colnames(keep))])))

#combine into one result df; view the new 'sample_depth' dataframe for comparisons
sample_depths <- bind_rows(
  depth = depth,
  depth_local_only = depth_local_only,
  depth_global_only = depth_global_only,
  depth_local_and_global = depth_local_and_global,
  .id = "source"
)
```

#### Proportions discarded with each subset
```{r}
sample_depths <- sample_depths %>%
   pivot_longer(cols = -source, names_to = "sample", values_to = "value") %>%
  pivot_wider(names_from = source, values_from = value) %>%
  group_by(sample) %>%
  mutate(prop_kept_local = depth_local_only / depth,
         prop_kept_global = depth_global_only / depth,
         prop_kept_both = depth_local_and_global / depth,
         reads_discarded = 1 - prop_kept_both,
         SampleID = substring(sample, 8, 13)) %>%
  ungroup() %>%
  left_join(data_samples %>%
              select(SampleID, Species), by = "SampleID")

write.csv(sample_depths, "./sample_depths.csv")
sample_depths 
```

#### Plot proportional changes at sample level if you add or don't add the global perfect matches to the local perfect matches
```{r}

ggplot(sample_depths, aes(x = prop_kept_local, y = prop_kept_both)) +
  geom_point(size=3) +
  geom_text_repel(aes(label = SampleID),
                  size=3)+
  labs(x = "Proportion Kept Locally", 
       y = "Proportion Kept Both Locally and Globally") +
  theme_minimal() +
  coord_cartesian(clip = "off")
```

```{r}
sample_depths %>% 
  gather(type, count, prop_kept_local:prop_kept_global:reads_discarded) %>% 
  filter(type != "prop_kept_both") %>%
  ggplot(., aes(x=sample, y=count, fill=forcats::fct_rev(type))) +
  scale_fill_manual(values = c("grey50", "#FFC20A", "#0C7BDC")) +
  geom_bar(stat="identity") +
  theme_classic()+
  theme(legend.title=element_blank(),
        axis.text.x=element_blank()) +
  scale_y_continuous(expand=c(0,0)) +
  facet_grid(. ~ Species, scales = "free", space = "free")
```
#### Print some important metrics overall
```{r}
#should be 90% to 80%
print(paste0("Overall proportion of reads retained with local and global combined: ", sprintf(sum(sample_depths$depth_local_and_global)/sum(sample_depths$depth),fmt='%#.3f')))

#should be 67% to 61%
print(paste0("Proportion of reads retained with just local: ", sprintf(sum(sample_depths$depth_local_only)/sum(sample_depths$depth),fmt='%#.3f')))

#should be 23% to 27%
print(paste0("Additional proportion of reads retained with just global: ", sprintf(sum(sample_depths$depth_global_only)/sum(sample_depths$depth),fmt='%#.3f')))
```

#### 100% matches in local that were new to global
```{r}
global_match <- data_global[which(data_global[[best_id_col]] == 1),]
global_missing <- subset(local_keep, !(id %in% global_match$id)) %>%
  arrange(desc(count))


depth_local_and_global <- colSums(keep[,grep("sample\\.", colnames(keep))])

global_missing_trim <- as.matrix(global_missing[,grep("sample\\.", colnames(global_missing[1,]))])


#What in the world is happening below here, lol?
global_missing_RRA <- as.data.frame(global_missing_trim %o% 1/depth_local_and_global)


global_missing_RRA_max <- round(apply(global_missing_RRA, 1, max, na.rm=TRUE), digits=6)
global_missing_RRA_mean <- round(apply(global_missing_RRA, 1, mean, na.rm=TRUE), digits=6)
global_missing_RRA_info <- cbind(global_missing[,1:10], global_missing[,382:387], global_missing_RRA_mean, global_missing_RRA_max, global_missing_RRA)
View(global_missing_RRA_info)
```


## Sample-wise Relative Read Abundance (RRA)

## Disproportionality

## Summarize local and non-trace global

## Summarize sample sizes

## Save outputs and generate Phyloseq object


